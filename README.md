# LLM-Unlearning

This repository contains a comprehensive collection of papers on LLM-Unlearning.


### Survey

- A gentle introduction to Unlearning: [Ken Liu blog](https://ai.stanford.edu/~kzliu/blog/unlearning)
  
- Rethinking Machine Unlearning for Large Language Models: [paper](https://arxiv.org/abs/2402.08787)

### Dataset

- TOFU - A Task of Fictitious Unlearning for LLMs: [paper](https://arxiv.org/pdf/2401.06121)
  
- WMDP Benchmark: [paper](https://www.wmdp.ai/)

## Unlearning methods

### Relabeling-based fine-tuning:

- Whoâ€™s harry potter? approximate unlearning in LLMs: [paper](https://arxiv.org/abs/2310.02238)
  
- Knowledge sanitization of large language models: [paper](https://arxiv.org/abs/2309.11852)
  
- TOFU - A Task of Fictitious Unlearning for LLMs: [paper](https://arxiv.org/pdf/2401.06121)

### In-context Learning:

- In-context unlearning- Language models as few shot unlearners: [paper](https://arxiv.org/abs/2310.07579)

### Gradient Ascent-based:

- Knowledge unlearning for mitigating privacy risks in language models Knowledge unlearning for mitigating
privacy risks in language models: [paper](https://arxiv.org/abs/2210.01504)

- Large language model unlearning: [paper](https://arxiv.org/pdf/2310.10683)
  

### Model Editing techniques:
- Detecting and editing privacy neurons in pre-trained language models: [paper](https://aclanthology.org/2023.emnlp-main.174/)

- Can sensitive information be deleted from LLMs? objectives for defending against extraction attacks: [paper](https://openreview.net/pdf?id=7erlRDoaV8)
  
- Privacy adhering machine un-learning in NLP: [paper](https://aclanthology.org/2023.findings-ijcnlp.25/)
  
- Unlearning bias in language models by partitioning gradients: [paper](https://aclanthology.org/2023.findings-acl.375.pdf)

### Reward-reinforced model-based:

- Controllable text generation with reinforced unlearning: [paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/b125999bde7e80910cbdbd323087df8f-Paper-Conference.pdf)
  

### KL-divergence-based methods:
-  A general machine unlearning framework based on knowledge gap alignment: [paper](https://arxiv.org/abs/2305.06535)
   
-  Unlearn what you want to forget: Efficient unlearning for LLMs: [paper](https://arxiv.org/abs/2310.20150)

### Vector-based PEFT via LoRA:
- Editing models with task arithmetic: [paper](https://openreview.net/forum?id=6t0Kwf8-jrj)

- Composing parameter-efficient modules with arithmetic operations: [paper](https://openreview.net/forum?id=5r3e27I9Gy&noteId=nnKn6sYNaV)

