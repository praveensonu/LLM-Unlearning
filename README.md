# LLM-Unlearning

This repository contains a comprehensive collection of papers on LLM-Unlearning.


### Survey

- A gentle introduction to Unlearning: [Ken Liu blog](https://ai.stanford.edu/~kzliu/blog/unlearning)
- Rethinking Machine Unlearning for Large Language Models: [paper](https://arxiv.org/abs/2402.08787)

### Dataset

- TOFU - A Task of Fictitious Unlearning for LLMs: [paper](https://arxiv.org/pdf/2401.06121)
- WMDP Benchmark: [paper](https://www.wmdp.ai/)

## Unlearning methods

### Relabeling-based fine-tuning:

- [Title](link-to-paper-1)
- [Title](link-to-paper-2)

### In-context Learning:

- In-context Learning: []()

### Gradient Ascent-based:

- Gradient Ascent-based FT: []()
- Fine-tuning with various objectives: []()

### Model Editing techniques
- Model editing techniques and constrained FT: []()

- SISA training via an adapter: []()

### Reward-reinforced model-based:

- Reward-reinforced model fine-tuning: []()
- Task vector-based PEFT via LoRA: []()
## Usage

To access the papers, navigate to the desired category and click on the link to the paper you want to read.

## Contributing

If you would like to contribute to this repository, please fork the repository and submit a pull request. For major changes, please open an issue first to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contact

For any questions or inquiries, please contact [Your Name](mailto:your-email@example.com).
